# -*- coding: utf-8 -*-
"""sklearn_DecisionTreeRegressor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ISnooIpr0Xoum0fAIMn4oQw_qtn1yTzx
"""

# Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from google.colab import drive
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import Lasso, Ridge
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

# Commented out IPython magic to ensure Python compatibility.
# Load data
drive.mount("/content/gdrive")  
!pwd 
# %cd "/content/gdrive/MyDrive/IA4DS/AprendizajeDeMaquina/FrameworkDeAprendizajeMaquina"
!ls 
df = pd.read_csv('data.csv') 
df.head()

# Get info of dataframe
print(df.info())

# Calculate duplicated values
print("Suma de duplicados: " + str(df.duplicated().sum()))

# Visualice data
df.plot(kind='scatter', x='height', y='weight')
plt.show()

# Assign x and y values
df_x=pd.DataFrame(df.height)
df_y=pd.DataFrame(df.weight)

# x values description
df_x.describe()

# Test train split for supervised training
x_train,x_test,y_train,y_test = train_test_split(df_x,df_y,test_size=0.2,random_state=4)

# Test train split visualization
plt.scatter(x_train, y_train, label='Training data', color='r', alpha=.7)
plt.scatter(x_test, y_test, label='Testing data', color='g', alpha=.7)
plt.legend()
plt.show()

# Create decision tree regressor model and train it
decTree=DecisionTreeRegressor()
decTree.fit(x_train,y_train)

# Use model to predict on test data
prediction=decTree.predict(x_test)

# Plot prediction line against actual test data
plt.plot(x_test, prediction, label='Linear regression', color='b')
plt.scatter(x_test, y_test, label='Actual test data', color='g', alpha=.7)
plt.legend()
plt.show()

# Test predictions 
prediction[1]

y_test

# Show real and predicted data 
fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9, 5))

axes[0].scatter(x_test, y_test, color='green', edgecolors='black', alpha=0.5)
axes[0].set_title("Real Test Data")

axes[1].scatter(x_test, prediction, color='orange', edgecolors='black', alpha=0.5)
axes[1].set_title("Predicted Test Data")

axes[2].scatter(x_test, y_test, color='green', edgecolors='black', alpha=0.5)
axes[2].scatter(x_test, prediction, color='orange', edgecolors='black', alpha=0.5)
axes[2].set_title("Real - Predicted")
fig.tight_layout()
plt.show()

# Calculate bias
data_true = 155.414139
data_predicted = prediction[1]
MBE = np.mean(data_predicted - data_true)
print("MBE: ", MBE)

# Calculate variance
import statistics
variance = statistics.variance(prediction) 
print(variance)

# Score the model
decTree.score(x_test, y_test)

decTree.score(x_train, y_train)

scores = cross_val_score(decTree, x_train, y_train, cv=5, scoring='r2')
print("Mean score of %0.2f with a standard deviation of %0.2f" % (scores.mean(), scores.std()))

# Lasso model regularization
lasso_reg = Lasso(alpha=0.3)
lasso_reg.fit(x_train, y_train)

lasso_reg.score(x_test, y_test)

lasso_reg.score(x_train, y_train)

# Ridge model regularization
ridge_reg = Ridge(alpha=0.3)
ridge_reg.fit(x_train, y_train)

ridge_reg.score(x_test, y_test)

ridge_reg.score(x_train, y_train)

# Lasso and ridge predictions
prediction_lasso=lasso_reg.predict(x_test)
prediction_ridge=ridge_reg.predict(x_test)

prediction_lasso=prediction_lasso.reshape(2000,1)
sns.distplot(y_test-prediction_lasso)

sns.distplot(y_test-prediction_ridge)